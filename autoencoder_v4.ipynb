{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M denotes the size of the message; k denotes the number of bits required to transmit the message; \n",
    "#n_channel denotes the number of channel uses required to transmit the message; R =k/n_channel is the message rate;\n",
    "#EbNodB denotes the signal-to-noise ratio at the receiver in dBm\n",
    "M = 25\n",
    "k = np.log2(M)\n",
    "k = int(k)\n",
    "n_channel = 7\n",
    "R = k/n_channel\n",
    "EbNodB = 5\n",
    "EbNo=10.0**(EbNodB/10.0)\n",
    "noise_mean = 0\n",
    "noise_std = np.sqrt(1/(2*R*EbNo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate training data \n",
    "N = 10000\n",
    "l = np.random.randint(M,size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create one hot encoded vectors of size M for training data\n",
    "data = []\n",
    "for i in l:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    data.append(temp)\n",
    "    \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate testing data \n",
    "Nt = 450\n",
    "test_l = np.random.randint(M,size=Nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create one hot encoded vectors of size M for testing data\n",
    "test_data = []\n",
    "for i in test_l:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    test_data.append(temp)\n",
    "    \n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrupt the channel with Gaussian noise\n",
    "def gaussian_noise_layer(input_layer, std):\n",
    "    noise = tf.random_normal(shape=tf.shape(input_layer), mean=noise_mean, stddev=noise_std, dtype=tf.float32) \n",
    "    return input_layer + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the autoencoder\n",
    "num_inputs=M\n",
    "num_hid1=n_channel\n",
    "num_hid2=num_hid1 \n",
    "num_output=num_inputs\n",
    "lr=0.01\n",
    "actf=tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=tf.placeholder(tf.float32,shape=[None,num_inputs])\n",
    "\n",
    "initializer=tf.variance_scaling_initializer()\n",
    "\n",
    "w1=tf.Variable(initializer([num_inputs,num_hid1]),dtype=tf.float32)\n",
    "w2=tf.Variable(initializer([num_hid1,num_hid2]),dtype=tf.float32)\n",
    "w3=tf.transpose(w1)\n",
    "\n",
    "b1=tf.Variable(tf.zeros(num_hid1))\n",
    "b2=tf.Variable(tf.zeros(num_hid2))\n",
    "b3=tf.Variable(tf.zeros(num_output))\n",
    "\n",
    "hid_layer1=tf.nn.relu(tf.matmul(S,w1)+b1)\n",
    "\n",
    "channel = gaussian_noise_layer(hid_layer1, noise_std)\n",
    "\n",
    "hid_layer2=tf.nn.relu(tf.matmul(channel,w2)+b2)\n",
    "\n",
    "output_layer=tf.nn.softmax(tf.matmul(hid_layer2,w3)+b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.square(output_layer-S))\n",
    "\n",
    "optimizer=tf.train.AdamOptimizer(lr)\n",
    "train=optimizer.minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For SNR 5 dBm, the BER is: 0.0\n"
     ]
    }
   ],
   "source": [
    "#train and test autoencoder; find the average bit error rate\n",
    "episodes = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    \n",
    "    for e in range(episodes):\n",
    "        for i in range(N):\n",
    "            input_ = data[i]\n",
    "            sess.run(train, feed_dict={S: [input_]})\n",
    "            \n",
    "    no_errors_avg = 0\n",
    "    for j in range(Nt):\n",
    "        input_ = test_data[j]\n",
    "        out_ = []\n",
    "        pred_final_signal=sess.run(output_layer, feed_dict = {S: [input_]})\n",
    "        pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "        temp = np.zeros(M)\n",
    "        temp[np.int(pred_output)] = 1\n",
    "        out_.append(temp)\n",
    "        out_ = np.array(out_)\n",
    "        no_errors = (out_ != input_)\n",
    "        no_errors =  no_errors.astype(int).sum()\n",
    "        no_errors_avg += no_errors\n",
    "    ber = no_errors_avg / Nt\n",
    "    print ('For SNR',EbNodB,'dBm, the BER is:',ber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
